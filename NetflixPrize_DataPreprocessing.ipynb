{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100498277, 2)\n",
      "-Dataset examples-\n",
      "          User_Id  Rating\n",
      "0              1:     NaN\n",
      "5000000   2560324     4.0\n",
      "10000000  2271935     2.0\n",
      "15000000  1921803     2.0\n",
      "20000000  1933327     3.0\n",
      "941737    1465002     3.0\n",
      "5941737    961023     4.0\n",
      "10941737  1372532     5.0\n",
      "15941737   854274     5.0\n",
      "20941737   116334     3.0\n",
      "25941737   768483     3.0\n",
      "3959435   1331144     5.0\n",
      "8959435   1609324     2.0\n",
      "13959435  1699240     3.0\n",
      "18959435  1776418     4.0\n",
      "1353649   1643826     5.0\n",
      "6353649    932047     4.0\n",
      "11353649  2292868     4.0\n",
      "16353649   932191     4.0\n",
      "21353649  1815101     3.0\n",
      "26353649   872339     4.0\n"
     ]
    }
   ],
   "source": [
    "# Skip date\n",
    "df1 = pd.read_csv('combined_data_1.txt', header = None, names = ['User_Id', 'Rating','Date'])\n",
    "df2 = pd.read_csv('combined_data_2.txt', header = None, names = ['User_Id', 'Rating','Date'])\n",
    "df3 = pd.read_csv('combined_data_3.txt', header = None, names = ['User_Id', 'Rating','Date'])\n",
    "df4 = pd.read_csv('combined_data_4.txt', header = None, names = ['User_Id', 'Rating','Date'])\n",
    "df = df1\n",
    "df = df1.append(df2)\n",
    "df = df.append(df3)\n",
    "df = df.append(df4)\n",
    "\n",
    "df['Rating'] = df['Rating'].astype(float)\n",
    "df = df.drop('Date', 1)\n",
    "\n",
    "print('Dataset shape: {}'.format(df.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])#START:STOP:STEP (5000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17770, 480189, 100480507)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index = np.arange(0,len(df))\n",
    "# get movie count (where rating ==NaN)\n",
    "movie_count = df.isnull().sum()[1] #df.isnull() searches for NaN values across all columns, we get in [1] column-rating\n",
    "\n",
    "# get customer count (amount of unique user_id-movie_id)\n",
    "user_count = df['User_Id'].nunique() - movie_count\n",
    "\n",
    "# get rating count (for ratings not only unique, all values except movies ids)\n",
    "rating_count = df['User_Id'].count() - movie_count\n",
    "\n",
    "movie_count, user_count , rating_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 100480507\n"
     ]
    }
   ],
   "source": [
    "#Movie ID is really a mess import! \n",
    "#Looping through dataframe to add Movie ID column WILL make the Kernel run out of memory as it is too inefficient. \n",
    "#I achieve my task by first creating a numpy array with correct length \n",
    "#then add the whole array as column into the main dataframe!\n",
    "\n",
    "#WORKING APPROXIMATELY 5 MIN\n",
    "\n",
    "df_nan = pd.DataFrame(pd.isnull(df.Rating)) #new df with indexes standard and one column \"Rating\" with True/False values\n",
    "#df1.Rating gets indexes+\"Rating\" column values\n",
    "#pd.isnull(df1.Rating) gets indexes+\"Rating\" mask column values (True=NaN, False-otherwise)\n",
    "\n",
    "df_nan = df_nan[df_nan['Rating'] == True]#new df with old indexes and one column \"Rating\" with only True values\n",
    "df_nan = df_nan.reset_index() # adds new indexes, old-moves to new column \"index\"\n",
    "\n",
    "\n",
    " # zip(df_nan['index'][1:],df_nan['index'][:-1]) returns iterator of tuples\n",
    "\n",
    "movie_np = []\n",
    "movie_id = 1 #we can start with 1 and sum it in loop,because all movie_id sorted in dataset from 1 to last (increase order)\n",
    "\n",
    "# i-current movie_id j-previous movie_id , its needed for counting the difference because\n",
    "#we need to know amount of rows=amount of ratings \n",
    "# so (i-j-1)=amount of not null ratings of whole users dataset for one movie (which has movie_id)\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,i-j-1), movie_id) # 1st arg-shape, second-value add row , because movie_np is array \n",
    "    temp\n",
    "    movie_np = np.append(movie_np, temp) # adds element to the end of array\n",
    "    movie_id += 1 #we can sum it in loop дшлу +1 ,because all movie_id sorted in dataset from 1 to last (increase order)\n",
    "    \n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)\n",
    "#finally after loop we get array movie_np size=amount of non null ratings, at each index it has corresponding \n",
    "#movie_id value for tis rating +can be concatenated with cleaned df\n",
    "print('Length: {}'.format(len(movie_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Dataset examples-\n",
      "           User_Id  Rating  Movie_Id\n",
      "1          1488844     3.0         1\n",
      "5000996     501954     2.0       996\n",
      "10001962    404654     5.0      1962\n",
      "15002876    886608     2.0      2876\n",
      "20003825   1193835     2.0      3825\n",
      "25004661   1899206     3.0      4661\n",
      "30005496    154804     4.0      5496\n",
      "35006274   2078749     5.0      6274\n",
      "40007057    450763     5.0      7057\n",
      "45007991    102092     3.0      7991\n",
      "50009023    220298     5.0      9023\n",
      "55010042    550530     5.0     10042\n",
      "60011038    222570     3.0     11038\n",
      "65011875   1273080     5.0     11875\n",
      "70012676   2026970     5.0     12676\n",
      "75013582    506044     4.0     13582\n",
      "80014453    353605     2.0     14453\n",
      "85015116    664606     3.0     15116\n",
      "90016008   2213715     3.0     16008\n",
      "95016879   1589401     5.0     16879\n",
      "100017627  2314006     4.0     17627\n"
     ]
    }
   ],
   "source": [
    "# remove those Movie ID rows from initial df (rows where rating=NaN)\n",
    "df = df[pd.notnull(df['Rating'])]\n",
    "\n",
    "df['Movie_Id'] = movie_np.astype(int) #Add movie_id column in df as movie_np received on previous step\n",
    "df['User_Id'] = df['User_Id'].astype(int)\n",
    "\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NetflixProcessedDataFile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

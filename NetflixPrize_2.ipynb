{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (24058263, 3)\n",
      "-Dataset examples-\n",
      "          User_Id  Rating        Date\n",
      "0              1:     NaN         NaN\n",
      "5000000   2560324     4.0  2005-12-06\n",
      "10000000  2271935     2.0  2005-04-11\n",
      "15000000  1921803     2.0  2005-01-31\n",
      "20000000  1933327     3.0  2004-11-10\n"
     ]
    }
   ],
   "source": [
    "# Skip date\n",
    "df1 = pd.read_csv('combined_data_1.txt', header = None, names = ['User_Id', 'Rating','Date'])\n",
    "\n",
    "df1['Rating'] = df1['Rating'].astype(float)\n",
    "\n",
    "print('Dataset 1 shape: {}'.format(df1.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df1.iloc[::5000000, :])#START:STOP:STEP (5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4499, 470758, 24053764)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.index = np.arange(0,len(df1))\n",
    "# get movie count (where rating ==NaN)\n",
    "movie_count = df1.isnull().sum()[1] #df.isnull() searches for NaN values across all columns, we get in [1] column-rating\n",
    "\n",
    "# get customer count (amount of unique user_id-movie_id)\n",
    "user_count = df1['User_Id'].nunique() - movie_count\n",
    "\n",
    "# get rating count (for ratings not only unique, all values except movies ids)\n",
    "rating_count = df1['User_Id'].count() - movie_count\n",
    "\n",
    "movie_count, user_count , rating_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 24053764\n"
     ]
    }
   ],
   "source": [
    "#Movie ID is really a mess import! \n",
    "#Looping through dataframe to add Movie ID column WILL make the Kernel run out of memory as it is too inefficient. \n",
    "#I achieve my task by first creating a numpy array with correct length \n",
    "#then add the whole array as column into the main dataframe!\n",
    "\n",
    "#WORKING APPROXIMATELY 5 MIN\n",
    "\n",
    "df_nan = pd.DataFrame(pd.isnull(df1.Rating)) #new df with indexes standard and one column \"Rating\" with True/False values\n",
    "#df1.Rating gets indexes+\"Rating\" column values\n",
    "#pd.isnull(df1.Rating) gets indexes+\"Rating\" mask column values (True=NaN, False-otherwise)\n",
    "\n",
    "df_nan = df_nan[df_nan['Rating'] == True]#new df with old indexes and one column \"Rating\" with only True values\n",
    "df_nan = df_nan.reset_index() # adds new indexes, old-moves to new column \"index\"\n",
    "\n",
    "\n",
    " # zip(df_nan['index'][1:],df_nan['index'][:-1]) returns iterator of tuples\n",
    "\n",
    "movie_np = []\n",
    "movie_id = 1 #we can start with 1 and sum it in loop,because all movie_id sorted in dataset from 1 to last (increase order)\n",
    "\n",
    "# i-current movie_id j-previous movie_id , its needed for counting the difference because\n",
    "#we need to know amount of rows=amount of ratings \n",
    "# so (i-j-1)=amount of not null ratings of whole users dataset for one movie (which has movie_id)\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,i-j-1), movie_id) # 1st arg-shape, second-value add row , because movie_np is array \n",
    "    temp\n",
    "    movie_np = np.append(movie_np, temp) # adds element to the end of array\n",
    "    movie_id += 1 #we can sum it in loop дшлу +1 ,because all movie_id sorted in dataset from 1 to last (increase order)\n",
    "    \n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "last_record = np.full((1,len(df1) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)\n",
    "#finally after loop we get array movie_np size=amount of non null ratings, at each index it has corresponding \n",
    "#movie_id value for tis rating +can be concatenated with cleaned df\n",
    "print('Length: {}'.format(len(movie_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Dataset examples-\n",
      "          User_Id  Rating        Date  Movie_Id\n",
      "1         1488844     3.0  2005-09-06         1\n",
      "5000996    501954     2.0  2004-08-26       996\n",
      "10001962   404654     5.0  2005-08-29      1962\n",
      "15002876   886608     2.0  2005-09-19      2876\n",
      "20003825  1193835     2.0  2003-08-13      3825\n"
     ]
    }
   ],
   "source": [
    "# remove those Movie ID rows from initial df (rows where rating=NaN)\n",
    "df1 = df1[pd.notnull(df1['Rating'])]\n",
    "\n",
    "df1['Movie_Id'] = movie_np.astype(int) #Add movie_id column in df as movie_np received on previous step\n",
    "df1['User_Id'] = df1['User_Id'].astype(int)\n",
    "print('-Dataset examples-')\n",
    "print(df1.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one hot encoding of column User_id\n",
    "#one_hot_users = pd.get_dummies(df1['User_Id'])\n",
    "#one_hot_users\n",
    "# Drop column User_Id as it is now encoded\n",
    "#df1 = df1.drop('User_Id',axis = 1)\n",
    "# Join the encoded df\n",
    "#df1 = df1.join(one_hot_users)\n",
    "#df1  \n",
    "\n",
    "#This approach with dummies wouldnt work, because dataset is too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veronika_Revyakina\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 264791)\t1.0\n",
      "  (1, 146632)\t1.0\n",
      "  (2, 157756)\t1.0\n",
      "  (3, 5365)\t1.0\n",
      "  (4, 146873)\t1.0\n",
      "  (5, 159340)\t1.0\n",
      "  (6, 22077)\t1.0\n",
      "  (7, 222084)\t1.0\n",
      "  (8, 327686)\t1.0\n",
      "  (9, 397671)\t1.0\n",
      "  (10, 267593)\t1.0\n",
      "  (11, 392334)\t1.0\n",
      "  (12, 460236)\t1.0\n",
      "  (13, 425)\t1.0\n",
      "  (14, 96982)\t1.0\n",
      "  (15, 215175)\t1.0\n",
      "  (16, 143503)\t1.0\n",
      "  (17, 193552)\t1.0\n",
      "  (18, 304537)\t1.0\n",
      "  (19, 66354)\t1.0\n",
      "  (20, 192402)\t1.0\n",
      "  (21, 221658)\t1.0\n",
      "  (22, 99569)\t1.0\n",
      "  (23, 384788)\t1.0\n",
      "  (24, 210278)\t1.0\n",
      "  :\t:\n",
      "  (24053739, 192931)\t1.0\n",
      "  (24053740, 233027)\t1.0\n",
      "  (24053741, 107764)\t1.0\n",
      "  (24053742, 54650)\t1.0\n",
      "  (24053743, 237582)\t1.0\n",
      "  (24053744, 188967)\t1.0\n",
      "  (24053745, 329447)\t1.0\n",
      "  (24053746, 47830)\t1.0\n",
      "  (24053747, 420612)\t1.0\n",
      "  (24053748, 94419)\t1.0\n",
      "  (24053749, 78800)\t1.0\n",
      "  (24053750, 371923)\t1.0\n",
      "  (24053751, 99100)\t1.0\n",
      "  (24053752, 54078)\t1.0\n",
      "  (24053753, 116865)\t1.0\n",
      "  (24053754, 48566)\t1.0\n",
      "  (24053755, 32896)\t1.0\n",
      "  (24053756, 394458)\t1.0\n",
      "  (24053757, 319568)\t1.0\n",
      "  (24053758, 455348)\t1.0\n",
      "  (24053759, 460485)\t1.0\n",
      "  (24053760, 318604)\t1.0\n",
      "  (24053761, 91453)\t1.0\n",
      "  (24053762, 176332)\t1.0\n",
      "  (24053763, 303210)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# importing one hot encoder from sklearn \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "encoder = OneHotEncoder()\n",
    "#X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']] \n",
    "#X-train matrix for encoder to learn categories\n",
    "#enc.fit(X)  #process of encoder learning categories\n",
    "one_hot_user_matrix = encoder.fit_transform(np.asarray(df1['User_Id']).reshape(-1,1)) \n",
    "print(one_hot_user_matrix[:, :]) #amount of rows=amount of ratings , amount of columns=amount of unique user_ids\n",
    "#enc.transform([['female', 'from US', 'uses Safari'],['male', 'from Europe', 'uses Safari']]).toarray()\n",
    "#finally transforming test matrix into one-hot-SLIGHTLY dont understand the output\n",
    "#array([[1., 0., 0., 1., 0., 1.],[0., 1., 1., 0., 0., 1.]])\n",
    "\n",
    "#df1 = df1.join(one_hot_user_matrix)\n",
    "#print(df1.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
